import datetime

import ckan.plugins as p
import logging
from collections import OrderedDict
from giftless_client import LfsClient
import ckan.model.license as core_licenses
import ckan.model.package as package
import ckan.plugins.toolkit as toolkit
import ckan.lib.uploader as uploader
from ckan.lib.plugins import DefaultTranslation
from ckan.logic import get_action
from werkzeug.datastructures import FileStorage as FlaskFileStorage
from ckanext.unaids.validators import (
    if_empty_guess_format,
    organization_id_exists_validator
)
from ckanext.unaids.helpers import (
    get_logo_path,
    get_all_package_downloads,
    get_autogenerated_resources,
    get_user_obj,
    get_all_organizations,
    get_bulk_file_uploader_default_fields,
)
from ckanext.unaids.blueprints.unaids_dataset_releases import get_dataset_release
import ckanext.external_storage.helpers as extstorage_helpers
import ckanext.blob_storage.helpers as blobstorage_helpers
import ckanext.unaids.actions as actions
from ckanext.unaids import (
    auth,
    licenses
)
from ckanext.unaids.blueprints import blueprints
from ckanext.reclineview.plugin import ReclineViewBase
from ckanext.validation.interfaces import IDataValidation
from ckanext.unaids.dataset_transfer.logic import send_dataset_transfer_emails

log = logging.getLogger(__name__)


def add_licenses():
    package.Package._license_register = core_licenses.LicenseRegister()
    package.Package._license_register.licenses = [
        core_licenses.License(
            licenses.LicenseCreativeCommonsIntergovernmentalOrgs()),
        core_licenses.License(
            core_licenses.LicenseNotSpecified())
    ]


class UNAIDSPlugin(p.SingletonPlugin, DefaultTranslation):
    """
    This plugin implements the configurations needed for AIDS data exchange

    """

    p.implements(p.IConfigurer)
    p.implements(p.IFacets, inherit=True)
    p.implements(p.IBlueprint)
    p.implements(p.ITranslation)
    p.implements(p.IConfigurer)
    p.implements(p.ITemplateHelpers)
    p.implements(p.IAuthFunctions)
    p.implements(p.IPackageController, inherit=True)
    p.implements(p.IResourceController, inherit=True)
    p.implements(p.IValidators)
    p.implements(p.IActions)
    p.implements(IDataValidation)

    # IConfigurer
    def update_config(self, config):
        '''
        This method allows to access and modify the CKAN configuration object
        '''
        add_licenses()
        log.info("UNAIDS Plugin is enabled")
        p.toolkit.add_template_directory(config, 'theme/templates')
        p.toolkit.add_public_directory(config, 'theme/public')
        toolkit.add_resource('assets', 'ckanext-unaids')

    def get_blueprint(self):
        return blueprints

    def get_actions(self):
        return {
            u'task_status_update': actions.task_status_update,
            u'get_table_schema': actions.get_table_schema
        }

    def dataset_facets(self, facet_dict, package_type):
        new_fd = OrderedDict()
        new_fd['organization'] = p.toolkit._('Organization')
        new_fd['type_name'] = p.toolkit._('Data Type')
        new_fd['tags'] = p.toolkit._('Tags')
        new_fd["year"] = p.toolkit._('Year')
        new_fd["geo-location"] = p.toolkit._('Location')
        return new_fd

    def organization_facets(self, facet_dict, org_type, package_type):

        return facet_dict

    # ITemplateHelpers
    def get_helpers(self):
        return {
            u'get_logo_path': get_logo_path,
            u'get_all_package_downloads': get_all_package_downloads,
            u'get_autogenerated_resources': get_autogenerated_resources,
            u'get_user_obj': get_user_obj,
            u'get_all_organizations': get_all_organizations,
            u'blob_storage_resource_filename': blobstorage_helpers.resource_filename,
            u'max_resource_size': uploader.get_max_resource_size,
            u'bulk_file_uploader_default_fields': get_bulk_file_uploader_default_fields,
            u'get_dataset_release': get_dataset_release,
        }

    # IAuthFunctions
    def get_auth_functions(self):
        return {
            'unaids_organization_update': auth.unaids_organization_update
        }

    def get_validators(self):
        return {
            'if_empty_guess_format': if_empty_guess_format,
            'organization_id_exists': organization_id_exists_validator
        }

    def can_validate(self, context, data_dict):
        if data_dict.get('validate_package'):
            logging.warning("VALIDATING ENTIRE PACKAGE")
            toolkit.get_action('resource_validation_run_batch')(
                context,
                {'dataset_ids': data_dict['package_id']}
            )
        if data_dict.get('schema'):
            return True

    # IPackageController
    def after_update(self, context, pkg_dict):
        if 'extras' in pkg_dict:
            org_to_allow_transfer_to = [
                item['value']
                for item in pkg_dict['extras']
                if item['key'] == 'org_to_allow_transfer_to' and item['value']
            ]
            if org_to_allow_transfer_to:
                send_dataset_transfer_emails(
                    dataset_id=pkg_dict['id'],
                    recipient_org_id=org_to_allow_transfer_to[0]
                )

    # IResourceController
    def before_create(self, context, resource):
        if _data_dict_is_resource(resource):
            _giftless_upload(context, resource)
        return resource

    def before_update(self, context, current, resource):
        if _data_dict_is_resource(resource):
            _giftless_upload(context, resource, current=current)
        return resource


class UNAIDSReclineView(ReclineViewBase):
    '''
    This override of the recline view plugin allows data explorers to be auto
    created for geojson files.
    '''

    def info(self):
        return {'name': 'unaids_recline_view',
                'title': 'Data Explorer',
                'filterable': True,
                'icon': 'table',
                'requires_datastore': False,
                'default_title': p.toolkit._('Data Explorer'),
                }

    def can_view(self, data_dict):
        resource = data_dict['resource']

        if (resource.get('datastore_active') or
                '_datastore_only_resource' in resource.get('url', '')):
            return True
        resource_format = resource.get('format', None)

        if resource_format:
            return resource_format.lower() in [
                'csv', 'xls', 'xlsx', 'tsv', 'geojson'
            ]
        else:
            return False


def _data_dict_is_resource(data_dict):
    return not (
            u'creator_user_id' in data_dict
            or u'owner_org' in data_dict
            or u'resources' in data_dict
            or data_dict.get(u'type') == u'dataset')


def _giftless_upload(context, resource, current=None):
    attached_file = resource.pop('upload', None)
    if attached_file:
        if type(attached_file) == FlaskFileStorage:
            dataset_id = resource.get('package_id')
            if not dataset_id:
                dataset_id = current['package_id']
            dataset = get_action('package_show')(
                context, {'id': dataset_id})
            dataset_name = dataset['name']
            org_name = dataset.get('organization', {}).get('name')
            authz_token = _get_upload_authz_token(
                context,
                dataset_name,
                org_name
            )
            lfs_client = LfsClient(
                lfs_server_url=blobstorage_helpers.server_url(),
                auth_token=authz_token,
                transfer_adapters=['basic']
            )
            uploaded_file = lfs_client.upload(
                file_obj=attached_file,
                organization=org_name,
                repo=dataset_name
            )

            lfs_prefix = blobstorage_helpers.resource_storage_prefix(dataset_name, org_name=org_name)
            resource.update({
                'url_type': 'upload',
                'last_modified': datetime.datetime.utcnow(),
                'sha256': uploaded_file['oid'],
                'size': uploaded_file['size'],
                'url': attached_file.filename,
                'lfs_prefix': lfs_prefix
            })


def _get_upload_authz_token(context, dataset_name, org_name):
    scope = 'obj:{}/{}/*:write'.format(org_name, dataset_name)
    authorize = toolkit.get_action('authz_authorize')
    if not authorize:
        raise RuntimeError("Cannot find authz_authorize; Is ckanext-authz-service installed?")
    authz_result = authorize(context, {"scopes": [scope]})
    if not authz_result or not authz_result.get('token', False):
        raise RuntimeError("Failed to get authorization token for LFS server")
    if len(authz_result['granted_scopes']) == 0:
        error = "You are not authorized to upload this resource."
        log.error(error)
        raise toolkit.NotAuthorized(error)
    return authz_result['token']
